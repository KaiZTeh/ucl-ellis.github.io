---
layout: dm_csml_seminar_event
posted_date: 2020-03-01
event_start_time: 2019-11-15 13:00
event_end_time: 2019-11-15 14:00
img: ellis-logo.png
alt: image-alt
join_link: Roberts Building G06 Sir Ambrose Fleming LT
location: Zoom
speaker: Varun Kanade
affiliation: University of Oxford
title: Implicit Regularization for Optimal Sparse Recovery
summary: <p>We present an implicit regularization scheme for gradient descent methods<br/>applied to unpenalized least squares regression to solve the problem of<br/>reconstructing a sparse signal from an underdetermined system of linear<br/>measurements under the restricted isometry assumption. For a given<br/>parameterization yielding a non-convex optimization problem, we show that<br/>prescribed choices of initialization, step size and stopping time yield a<br/>statistically and computationally optimal algorithm that achieves the minimax<br/>rate with the same cost required to read the data up to poly-logarithmic<br/>factors. Beyond minimax optimality, we show that our algorithm adapts to<br/>instance difficulty and yields a dimension-independent rate when the<br/>signal-to-noise ratio is high enough. We validate our findings with numerical<br/>experiments and compare our algorithm against explicit $\ell_{1}$ penalization.<br/>Going from hard instances to easy ones, our algorithm is seen to undergo a<br/>phase transition, eventually matching least squares with an oracle knowledge of<br/>the true support.</p><p>(based on joint work with Patrick Rebeschini and Tomas Vaskevicius)</p><p>Varun Kanade is an associate professor at University of Oxford in the Department of Computer Science. He has been a Simons Postdoctoral Fellow at the University of California, Berkeley and a FSMP postdoctoral fellow at ENS, Paris. He obtained his Ph.D. from Harvard University in 2012. His research interests are in machine learning and theoretical computer science.</p>
icalendar: /ics/id/398
calendar_name: csml_id_398.ics
old_url: http://www.csml.ucl.ac.uk/events/398
---
