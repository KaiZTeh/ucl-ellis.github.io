---
layout: dm_csml_seminar_event
posted_date: 2020-03-01
event_start_time: 2013-01-11 12:30
event_end_time: 2013-01-11 14:00
img: ellis-logo.png
alt: image-alt
join_link: Cruciform B404 - LT2
location: Zoom
speaker: Ed Challis
affiliation: UCL
title: Variational approximate inference in linear latent variable models
summary: <p>Linear latent variable models (such as factor analysis and probabilistic principal components analysis) and Bayesian generalized linear models (such as logistic regression and noise robust linear regression) are used widely throughout Machine Learning and Statistics. However, in all but the simplest cases inference remains computationally intractable.</p><p>This talk will focus on parametric Kullback-Leibler approximate inference methods as applied to such models. Parametric Kullback-Leibler approximate inference provides both a parametric approximation to the intractable posterior and lower bound to its normalisation constant. I will present my work on developing Gaussian KL approximate inference methods and introduce a new flexible approximating density class for which parametric KL inference is tractable and efficient.</p><p>Slides for the talk&#58; <a href="http&#58;//events.csml.ucl.ac.uk/userdata/lunch_talks/2013_01_11_ec.pdf">PDF</a></p>
icalendar: /ics/id/77
calendar_name: csml_id_/77.ics
old_url: http://www.csml.ucl.ac.uk/events/77
---
