---
layout: dm_csml_seminar_event
posted_date: 2020-03-01
event_start_time: 2020-02-27 13:00
event_end_time: 2020-02-27 14:00
img: ellis-logo.png
alt: image-alt
join_link: Roberts 106
location: Zoom
speaker: Aude Genevay
affiliation: MIT
title: Learning with entropy-regularized optimal transport
summary: <p>Abstract&#58; Entropy-regularized OT (EOT) was first introduced by Cuturi in 2013 as a solution to the computational burden of OT for machine learning problems. In this talk, after studying the properties of EOT, we will introduce a new family of losses between probability measures called Sinkhorn Divergences. Based on EOT, this family of losses actually interpolates between OT (no regularization) and MMD (infinite regularization). We will illustrate these theoretical claims on a set of learning problems formulated as minimizations over the space of measures. </p><p>Bio&#58; Aude Genevay is a postdoctoral researcher in the Geometric Data Processing group at MIT, working with Justin Solomon. Prior to that she obtained at PhD in Mathematics from Ecole Normale Supérieure under the supervision of Gabriel Peyré.</p>
icalendar: /ics/id/408
calendar_name: csml_id_408.ics
old_url: http://www.csml.ucl.ac.uk/events/408
---
