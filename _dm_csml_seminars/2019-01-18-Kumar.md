---
layout: dm_csml_seminar_event
posted_date: 2020-03-01
event_start_time: 2019-01-18 13:00
event_end_time: 2019-01-18 14:00
img: ellis-logo.png
alt: image-alt
join_link: Roberts 421
location: Zoom
speaker: Sesh Kumar
affiliation: Imperial College
title: Differentially Private Empirical Risk Minimization with Sparsity-Inducing Norms
summary: <p>Abstract. Differential privacy is concerned about the prediction quality while measuring the privacy impact on individuals whose information is contained in the data. We consider differentially private risk minimization problems with regularizers that induce structured sparsity. These regularizers are known to be convex but they are often non-differentiable. We analyze the standard differentially private algorithms, such as output perturbation and objective perturbation. Output perturbation is a differentially private algorithm that is known to perform well for minimizing risks that are strongly convex. Previous works have derived dimensionality independent excess risk bounds for these cases. In this paper, we assume a particular class of convex but non-smooth regularizers that induce structured sparsity and loss functions for generalized linear models. We derive excess risk bound for output perturbation that is independent of the dimensionality of the problem. We also show that the existing analysis for objective perturbation may be extended to these risk minimization problems.</p>
icalendar: /ics/id/366
calendar_name: csml_id_366.ics
old_url: http://www.csml.ucl.ac.uk/events/366
---
