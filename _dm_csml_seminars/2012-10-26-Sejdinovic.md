---
layout: dm_csml_seminar_event
posted_date: 2020-03-01
event_start_time: 2012-10-26 12:30
event_end_time: 2012-10-26 14:00
img: ellis-logo.png
alt: image-alt
join_link: Cruciform B404 - LT2
location: Zoom
speaker: Dino Sejdinovic
affiliation: UCL
title: Equivalence of distance-based and RKHS-based statistics in hypothesis testing
summary: <p>We provide a unifying framework linking two classes of statistics used in two-sample and independence testing&#58; on the one hand, the energy distances and distance covariances from the statistics literature; on the other, Maximum Mean Discrepancies (MMD), i.e., distances between embeddings of distributions to reproducing kernel Hilbert spaces (RKHS), as established in machine learning. In the case where the energy distance is computed with the semimetric of negative type, a positive definite kernel, termed distance kernel, may be defined such that the MMD corresponds exactly to the energy distance. Conversely, for any positive definite kernel, we can interpret the MMD as energy distance with respect to some negative-type semimetric. This equivalence readily extends to the case of independence testing using kernels on the product space. We determine the class of probability distributions for which the test statistics are consistent against all alternatives. Finally, we investigate the performance of the family of distance kernels in two-sample and independence tests.</p><p>Slides for the talk&#58; <a href="http&#58;//events.csml.ucl.ac.uk/userdata/lunch_talks/2012_10_26_ds.pdf">PDF</a></p>
icalendar: /ics/id/73
calendar_name: csml_id_/73.ics
old_url: http://www.csml.ucl.ac.uk/events/73
---
