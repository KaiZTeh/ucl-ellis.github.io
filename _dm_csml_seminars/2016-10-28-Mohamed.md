---
layout: dm_csml_seminar_event
posted_date: 2020-03-01
event_start_time: 2016-10-28 13:00
event_end_time: 2016-10-28 14:00
img: ellis-logo.png
alt: image-alt
join_link: Roberts Building 508
location: Zoom
speaker: Shakir Mohamed
affiliation: Google DeepMind
title: Building Machines that Imagine and Reason&#58; Principles and Applications of Deep Generative Models
summary: <p>Deep generative models provide a solution to the problem of unsupervised learning, in which a machine learning system is required to discover the structure hidden within unlabelled data streams. Because they are generative, such models can form a rich imagery the world in which they are used&#58; an imagination that can harnessed to explore variations in data, to reason about the structure and behaviour of the world, and ultimately, for decision-making. This tutorial looks at how we can build machine learning systems with a capacity for imagination using deep generative models, the types of probabilistic reasoning that they make possible, and the ways in which they can be used for decision making and acting.</p><p>Deep generative models have widespread applications including those in density estimation, image de-noising and in-painting, data compression, scene understanding, representation learning, 3D scene construction, semi-supervised classification, and hierarchical control, amongst many others. After exploring these applications, we'll sketch a landscape of generative models, drawing-out three groups of models&#58; fully-observed models, transformation models, and latent variable models. Different models require different principles for inference and we'll explore the different options available. Different combinations of model and inference give rise to different algorithms, including auto-regressive distribution estimators, variational auto-encoders, and generative adversarial networks. Although we will emphasise deep generative models, and the latent-variable class in particular, the intention of the tutorial will be to explore the general principles, tools and tricks that can be used throughout machine learning. These reusable topics include Bayesian deep learning, variational approximations, memoryless and amortised inference, and stochastic gradient estimation. We'll end by highlighting the topics that were not discussed, and imagine the future of generative models.<br/></p>
icalendar: /ics/id/317
calendar_name: csml_id_317.ics
old_url: http://www.csml.ucl.ac.uk/events/317
---
