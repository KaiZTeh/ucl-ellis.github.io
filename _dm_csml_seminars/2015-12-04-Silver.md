---
layout: dm_csml_seminar_event
posted_date: 2020-03-01
event_start_time: 2015-12-04 13:00
event_end_time: 2015-12-04 14:00
img: ellis-logo.png
alt: image-alt
join_link: Roberts G08 (Sir David Davies lecture theatre)
location: Zoom
speaker: Stephen Pasteris, Wittawat Jitkrittum, Ricardo Silver
affiliation: UCL
title: NIPS previews
summary: <p>Talk 1&#58; Stephen Pasteris will present</p><p>Online Prediction at the Limit of Zero Temperature</p><p>by Mark Herbster and Stephen Pasteris</p><p>Abstract&#58;</p><p>We design an online algorithm to classify the vertices of a graph. Underpinning the algorithm is the probability distribution of an Ising model isomorphic to the graph. Each classification is based on predicting the label with maximum marginal probability in the limit of zero-temperature with respect to the labels and vertices seen so far. Computing these classifications is unfortunately based on a #P- complete problem. This motivates us to develop an algorithm for which we give a sequential guarantee in the online mistake bound framework. Our algorithm is optimal when the graph is a tree matching the prior results in [?]. For a general graph, the algorithm exploits the additional connectivity over a tree to provide a per-cluster bound. The algorithm is efficient, as the cumulative time to sequen- tially predict all of the vertices of the graph is quadratic in the size of the graph.</p><p>Talk 2&#58; Wittawat Jitkrittum will present</p><p>Bayesian Manifold Learning&#58; The Locally Linear Latent Variable Model</p><p>by</p><p>Mijung Park, Wittawat Jitkrittum,  Ahmad Qamar, Zoltan Szabo,  Lars Buesing,  Maneesh Sahani</p><p>Abstract&#58; We introduce the Locally Linear Latent Variable Model (LL-LVM), a probabilistic model for non-linear manifold discovery that describes a joint distribution over observations, their manifold coordinates and locally linear maps conditioned on a set of neighbourhood relationships. The model allows  straightforward variational optimisation of the posterior distribution on coordinates and locally linear maps from the latent space to the observation space given the data.  Thus, the LL-LVM encapsulates the local-geometry preserving intuitions that underlie non-probabilistic methods such as locally linear embedding<br/>(LLE). Its probabilistic semantics make it easy to evaluate the quality of hypothesised neighbourhood relationships, select the intrinsic dimensionality of the manifold, construct out-of-sample extensions and to combine the manifold model with additional probabilistic models that capture the structure of coordinates within the manifold.</p><p>Talk 3&#58;  Ricardo Silver will present</p><p>Bandits with Unobserved Confounders&#58; A Causal Approach</p><p>by</p><p>Elias Bareinboim<br/>Andrew Forney<br/>Judea Pearl</p><p>The Multi-Armed Bandit problem constitutes an archetypal setting for sequential<br/>decision-making, permeating multiple domains including engineering, business,<br/>and medicine.   One of the hallmarks of a bandit setting is the agentâ€™s capacity<br/>to explore its environment through active intervention, which contrasts with the<br/>ability to collect passive data by estimating associational relationships between<br/>actions and payouts.  The existence of unobserved confounders, namely unmea-<br/>sured variables affecting both the action and the outcome variables, implies that<br/>these two data-collection modes will in general not coincide.  In this paper, we<br/>show that formalizing this distinction has conceptual and algorithmic implications<br/>to the bandit setting. The current generation of bandit algorithms implicitly try to<br/>maximize  rewards  based  on  estimation  of  the  experimental  distribution,  which<br/>we show is not always the best strategy to pursue.  Indeed, to achieve low regret<br/>in certain realistic classes of bandit problems (namely, in the face of unobserved<br/>confounders), both experimental and observational quantities are required by the<br/>rational agent. After this realization, we propose an optimization metric (employ-<br/>ing both experimental and observational distributions) that bandit agents should<br/>pursue, and illustrate its benefits over traditional algorithms.</p><p>http&#58;//ftp.cs.ucla.edu/pub/stat_ser/r460.pdf</p>
icalendar: /ics/id/246
calendar_name: csml_id_246.ics
old_url: http://www.csml.ucl.ac.uk/events/246
---
