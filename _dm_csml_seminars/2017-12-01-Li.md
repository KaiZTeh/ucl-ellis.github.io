---
layout: dm_csml_seminar_event
posted_date: 2020-03-01
event_start_time: 2017-12-01 13:00
event_end_time: 2017-12-01 14:00
img: ellis-logo.png
alt: image-alt
join_link: Roberts Building G08 Sir David Davies LT
location: Zoom
speaker: Yingzhen Li
affiliation: University of Cambridge
title: Wild approximate inference&#58; why and how
summary: <p>This talk describes very recent efforts on developing approximate inference algorithms that enables approximations of arbitrary form. I will start by revisiting fundamental tractability issues of Bayesian computation and argue that density evaluation of the approximate posterior is mostly unnecessary. Then I will present 4 different categories of wild approximate inference methods that has been explored recently, with the focus on two of them developed by myself and colleagues. I will briefly cover&#58; 1. the amortised MCMC algorithm that improves the approximate posterior by following the particle update of a valid MCMC sampler; and 2. a gradient estimation method that allow variational inference to be applied to those approximate distributions without a tractable density. </p>
icalendar: /ics/id/328
calendar_name: csml_id_328.ics
old_url: http://www.csml.ucl.ac.uk/events/328
---
