---
layout: dm_csml_seminar_event
posted_date: 2020-03-01
event_start_time: 2018-06-08 13:00
event_end_time: 2018-06-08 14:00
img: ellis-logo.png
alt: image-alt
join_link: Roberts Building G08 Sir David Davies LT
location: Zoom
speaker: Edward Grefenstette
affiliation: DeepMind
title: Learning to follow grounded language instructions in the "real" world
summary: <p>Reinforcement Learning (RL) generally presupposes the availability of possibly sparse–but primarily correct–reward signal from the environment, with which to reward an agent for behaving appropriately within the context of a task. Teaching agents to follow instructions using RL is a quintessentially multi-task problem&#58; each instruction in a possibly combinatorially rich language corresponds to a specific task for which there must be a reward function against which the agent will learn. This has largely limited the RL community, thus far, to forms of instruction languages (e.g. templated instructions) where families of reward functions can be specified, and individual reward functions can be generated. In this talk, I discuss a new method which will allow us to take a step towards RL "in the wild", exploring a richer set of instruction languages, and enabling us to expose agents to a rich variety of tasks without needing to perpetually design reward functions over environment states.</p>
icalendar: /ics/id/353
calendar_name: csml_id_353.ics
old_url: http://www.csml.ucl.ac.uk/events/353
---
